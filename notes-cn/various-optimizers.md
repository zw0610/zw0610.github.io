# ä¼˜åŒ–å™¨ All-in-One

ä»Šå¤©é¢è¯•çš„æ—¶å€™åˆè¢«é—®åˆ°äº†å…³äºå„ç§ optimizers çš„é—®é¢˜ï¼Œä»€ä¹ˆ RMSProp æ˜¯ä»€ä¹ˆã€è·Ÿ Adamã€Momentum çš„åŒºåˆ«åœ¨å“ªé‡Œã€‚æˆ‘åˆä¸€æ¬¡æ²¡è®°ä½ï¼Œæ¯•ç«Ÿå¹³æ—¶éƒ½æ˜¯åšå·¥ç¨‹çš„ã€‚ç„¶åå½“æˆ‘ç»“æŸåå»æŸ¥è¯¢çš„æ—¶å€™ï¼Œå‘ç°ä¸­æ–‡ç¤¾åŒºå¯¹ä¸ Optimizers çš„æ€»ç»“çœŸæ˜¯ä¸€è¨€éš¾å°½ã€‚ç§‰æ‰¿è¿™â€œå¥½è®°æ€§ä¸å¦‚çƒ‚ç¬”å¤´â€çš„å®—æ—¨ï¼Œè¿˜æ˜¯æŠŠè‡ªå·±çœ‹æ–‡ç« çš„æ”¶è·è®°ä¸‹æ¥ï¼Œä»¥å¤‡ä¸‹æ¬¡é¢è¯•æ—¶ä¼šç”¨åˆ°ã€‚

## Baseline SGD with Momentum

é‰´äºå¾ˆå¤šæ·±åº¦å­¦ä¹ æ¡†æ¶ç›´æ¥æŠŠå¸¦ Momentum çš„ SGD å½“ä½œ default SGD optimizerï¼Œè¿™é‡Œå°±æŠŠä»–ä»¬åˆåœ¨ä¸€ä¸ªç« èŠ‚é‡Œï¼Œä½œä¸º Baselineã€‚



### Mini-Batch SGD

Gradient Descent çš„æ ¸å¿ƒæ€æƒ³éå¸¸çš„ç®€å•ã€‚é’ˆå¯¹ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬æœ€ç»ˆå¸Œæœ›å®ƒçš„ï¼ˆéè´Ÿçš„ï¼‰æŸå¤±å‡½æ•°æœ€å°ï¼š`ğœ½ = argmin J(ğœ½)`ã€‚

æ ¹æ® [Gradient Descent on Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)ï¼ŒGD ç§‰æŒä¸€ä¸ªæœ€æœ´ç´ çš„æ€æƒ³ï¼š`J'(ğœ½)` æŒ‡å‘å“ªé‡Œï¼Œæ²¿ç€å®ƒçš„åæ–¹å‘ `-J'(ğœ½)` èµ°ï¼ˆå³ `ğœ½_next = ğœ½_now - J'(ğœ½)`ï¼‰ï¼Œå°±èƒ½è®© `J(ğœ½)` é™ä½ã€‚è¿™ä¸ªæ€æƒ³ç”šè‡³æ¯”é«˜æ–¯è¿­ä»£è¿˜è¦æ¥å¾—æ›´æœ´ç´ ã€‚

ç„¶è€Œä¸€æ¬¡æ€§è®¡ç®—åšå…¨æ ·æœ¬çš„æ¢¯åº¦è®¡ç®—æ˜¯éå¸¸æ˜‚è´µçš„ï¼Œè®¡ç®—èµ„æºä¸è¯´ï¼Œæ˜¾å­˜çš„å ç”¨ææ€•å°±è®© GPU æœ›è€Œå´æ­¥ã€‚æ‰€ä»¥ä¸€èˆ¬éƒ½é‡‡å– Mini-Batch çš„æ–¹æ³•ï¼Œå³æŠŠå…¨é‡æ•°æ®æ‹†åˆ†æˆ N ä¸ª Batchesï¼Œç„¶åæ¯è¿‡ä¸€ä¸ª Batchï¼Œå°±æ›´æ–°ä¸€ä¸‹ `ğœ½`ã€‚ç›¸äº¤ SGDï¼Œç¡®å®æ²¡æœ‰é‚£ä¹ˆæ˜‚è´µäº†ï¼Œä½†æ˜¯ä»æ”¶æ•›ç¨³å®šçš„è§’åº¦è®²ï¼Œä¸å¦‚å…¨é‡æ•°æ®çš„ SGDã€‚åŸå› åœ¨äºï¼Œå…¨é‡æ•°æ® SGD åœ¨æ›´æ–°æ¢¯åº¦æ—¶ï¼Œå¯ä»¥ç«™åœ¨å…¨å±€æ•°æ®ç»™å‡ºçš„è§’åº¦è®¡ç®—å‡ºæœ€ä¸ºç²¾ç¡®çš„æ¢¯åº¦ï¼›è€Œåœ¨ Mini-Batch å¼•å…¥ä¹‹åï¼Œæ¯ä¸€æ¬¡æ¢¯åº¦çš„æ›´æ–°éƒ½æ˜¯ç›¸å¯¹äºå…¨é‡æ•°æ®çš„å±€éƒ¨æ¢¯åº¦ï¼Œé¢‡æœ‰ï¼ˆåŠï¼‰ç›²äººæ‘¸è±¡çš„æ„Ÿè§‰ã€‚

### Momentum & Nesterov Momentum

åˆšåˆšæåˆ°äº† Mini-Batch çš„ä¸€ä¸ªç¼ºé™·ï¼Œå°±æ˜¯æ¯æ¬¡æ›´æ–° ğœ½ çš„æ—¶å€™ï¼Œç”±äºä»…ç«‹è¶³ä¸ä¸€ä¸ªå°æ‰¹æ ·æœ¬ï¼Œå¦‚æœè¿™å°æ‰¹æ ·æœ¬å’Œå…¨å±€æ ·æœ¬çš„åˆ†å¸ƒæœ‰è¾ƒå¤§çš„å·®å¼‚çš„è¯ï¼Œé‚£ä¹ˆè¿™ä¸€æ¬¡æ¢¯åº¦æ›´æ–°å°±ä¼šè¾ƒå¤§ç¨‹åº¦ä¸Šåœ°åç¦»æœ€ç»ˆçš„ ğœ½_optimalã€‚äº‹å®ä¸Šï¼Œæ¯ä¸€ä¸ª Mini-Batch å…¶å®éƒ½ä¼šé€ æˆæ¢¯åº¦æ›´æ–°çš„åç¦»ã€‚

é‚£å¦‚ä½•è§£å†³å‘¢ï¼Ÿæœ‰ä¸€ä¸ªåŠæ³•è·Ÿ Gaussâ€“Seidel æ–¹æ³•è¡ç”Ÿå‡ºæ¥çš„ Successive Over-Relaxation (SOR) é¢‡æœ‰ç±»ä¼¼ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå°±æ˜¯*æ—¢ç„¶è¿™ä¸€æ¬¡æ›´æ–°å¯èƒ½ä¼šèµ°åï¼Œé‚£æˆ‘å°±ä¸è¦å…¨é€Ÿæ›´æ–°ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šä¿æœ‰åŸæœ‰çš„å€¼*ï¼ˆé¢‡æœ‰[ä¸¤ä¸ªåŸºæœ¬ç‚¹](https://zh.wikipedia.org/wiki/%E4%B8%80%E4%B8%AA%E4%B8%AD%E5%BF%83%E3%80%81%E4%B8%A4%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%82%B9)çš„æ„æ€ï¼‰ã€‚

Momentum åœ¨ DL ä¸Šçš„çš„å…·ä½“æ–¹æ³•æˆ‘æŸ¥é˜…äº† [On the importance of initialization and momentum in deep learning](http://www.cs.utoronto.ca/~ilya/pubs/2013/1051_2.pdf)ã€‚

æœ€ä¸ºåŸå§‹çš„ Momentum æ–¹æ³•å³ä¸ºåˆ©ç”¨ä¸Šä¸€æ¬¡æ›´æ–°çš„æ–¹å‘åšä¸€æ¬¡â€œçº åâ€ï¼š

```
v_t+1 = ğv_t - ğœºJ'(ğœ½_t)
ğœ½_t+1 = ğœ½_t + v_t+1
```

å…¶ä¸­ï¼Œ`ğœº` æ˜¯å­¦ä¹ ç‡ï¼Œ`ğ` åˆ™ä¸ºä¸€ä¸ªå–å€¼ `[0,1]` çš„åŠ¨é‡ç³»æ•°ã€‚

æ¥ä¸‹å»ä¼šæœ‰ä¸€ç§æ”¹è¿›ç‰ˆçš„ Momentum æ³•ï¼šNesterov's Momentumã€‚

```
v_t+1 = ğv_t - ğœºJ'(ğœ½_t + ğv_t)
ğœ½_t+1 = ğœ½_t + v_t+1
```

é€šè¿‡å¯¹æ¯”ï¼Œå¯ä»¥å¾ˆæ˜æ˜¾åœ°çŸ¥é“ï¼ŒNesterov æ³•å…¶å®å°±æ˜¯åœ¨è®¡ç®—æ¢¯åº¦æ—¶ï¼Œ å¹¶ä¸æ˜¯ä»å½“å‰ `ğœ½_t` å‡ºå‘è¿›è¡Œè®¡ç®—ï¼Œè€Œæ˜¯å‡è®¾èµ°ä¸€æ­¥ `ğv_t` ä¹‹åçš„ä¸­é—´å€¼ã€‚è¿™ç§æå‰èµ°åŠæ­¥çš„æ–¹æ³•å¯ä»¥åœ¨ä¸€å®šæ¡ä»¶ä¸‹åŠ é€Ÿæ¨¡å‹å‚æ•°çš„æ”¶æ•›ã€‚

## ä¼—å£éš¾è°ƒï¼Ÿ

åœ¨è§£å†³äº† Mini-Batch å¸¦æ¥çš„æŠ–åŠ¨é—®é¢˜ä¹‹åï¼Œè¿˜æœ‰ä¸€ä¸ªé—®é¢˜å›°æ‰°ç€ DL æ¨¡å‹çš„ä¼˜åŒ–ï¼Œå³å¤šå‚æ•°å¸¦æ¥çš„é—®é¢˜ã€‚æ‰€è°“å¤šå‚æ•°ï¼Œå°±æ˜¯è¯´æˆ‘ä»¬ä¸Šé¢çœ‹åˆ°çš„ `ğœ½` å…¶å®å¯èƒ½æ˜¯ä¸€ä¸ªé•¿åº¦è¶…è¿‡ç™¾ä¸‡çš„å‘é‡ã€‚å°¤å…¶æ˜¯éšç€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¤æ‚åŒ–ï¼Œå‚æ•°çš„æ•°é‡ä¹Ÿåœ¨è†¨èƒ€ã€‚å¯ä»¥æƒ³åƒï¼Œç”¨ä¸€ä¸ªå•ä¸€çš„å­¦ä¹ ç‡ä½œç”¨äºæ‰€æœ‰çš„å‚æ•°ï¼Œå…¶å¸¦æ¥çš„æ¢¯åº¦æ›´æ–°çš„æ•ˆæœå¿…ç„¶ä¼šæ”¶åˆ°æ¯”è¾ƒå¤§çš„å½±å“ï¼ˆæœ‰çš„å‚æ•°å·²ç»æ¯”è¾ƒæ¥è¿‘ optimal äº†ï¼Œè€Œæœ‰çš„è¿˜å·®å¾ˆè¿œï¼‰ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œåˆæœ‰å“ªå‡ ç§è§£å†³åŠæ³•å‘¢ï¼Ÿ

### RMSProp
Root Mean Square Propagationï¼ˆRMSPropï¼‰è¿™ç§æ–¹æ³•æœ€å¼€å§‹ä» Cousera ä¸Šçš„ [slice](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf) èµ·å®¶ï¼Œå¾ˆå¿«æ”¶åˆ°å¤§å®¶çš„æ¬¢è¿ã€‚å…¶æ ¸å¿ƒçš„æ€æƒ³å°±æ˜¯é’ˆå¯¹æ¯ä¸€ä¸ªå‚æ•°ï¼Œéƒ½åˆ©ç”¨å…¶ä¹‹å‰å‡ æ¬¡çš„æ¢¯åº¦æ›´æ–°æ¥è°ƒæ•´è¿™æ¬¡æ›´æ–°éœ€è¦æ€æ ·çš„å­¦ä¹ ç‡ã€‚

å¦‚æœä¸è€ƒè™‘å…·ä½“çš„æ¢¯åº¦å€¼ï¼Œåªè€ƒè™‘æ¢¯åº¦çš„ç¬¦å·ï¼ˆå³æ–¹å‘ï¼‰ï¼ŒRProp æœ‰è¿™æ ·ä¸€æ¡è§„å¾‹ï¼š

1. å¦‚æœè¿‡å»ä¸¤æ¬¡æ›´æ–°çš„æ¢¯åº¦ç¬¦å·ç›¸åŒï¼Œä»£è¡¨æ–¹å‘æ­£ç¡®ï¼Œå¢å¤§æ›´æ–°æ—¶çš„æ­¥é•¿
2. å¦‚æœè¿‡å»ä¸¤æ¬¡æ›´æ–°çš„æ¢¯åº¦ç¬¦å·ç›¸åï¼Œä»£è¡¨æ–¹å‘ä¸å®šï¼Œç¼©å°æ›´æ–°æ—¶çš„æ­¥é•¿

ç„¶è€Œè¿™ç§æ–¹æ³•åœ¨ Mini-Batch ä¸Šå´ä¸å¥½ã€‚æ¯ä¸ª Mini-Batch ä¹‹é—´çš„å·®åˆ«ä¼šä½¿å¾—æ¯ä¸€æ¬¡æ›´æ–°æœ¬èº«çš„æ­¥é•¿å°±ä¼šæœ‰å¾ˆå¤§çš„å·®å¼‚ï¼Œè¿™ä¸€ç‚¹å’Œå…¨é‡æ•°æ®æ›´æ–°æ—¶æœ‰æ¯”ä»·æ˜æ˜¾çš„å·®å¼‚ã€‚è¿™æ ·ä¸€æ¥ï¼Œå•çº¯ä¾é ç¬¦å·å°±æ˜¾å¾—åŠ›ä¸ä»å¿ƒäº†ã€‚æˆ‘ä»¬éœ€è¦åŠ ä¸Šä¾èµ–æ•°å€¼çš„ä¼°è®¡æ¥å¼¥åˆ Mini-Batch å¸¦æ¥çš„å·®å¼‚ã€‚

æˆ‘ä»¬å…ˆæ¥è®¡ç®—å·²ç»ç´¯ç§¯çš„æ¢¯åº¦çš„å‡æ–¹å·®ï¼Œè¿™é‡Œå¼•å…¥ä¸€ä¸ªé—å¿˜ï¼ˆæˆ–é˜»å°¼ï¼‰ç³»æ•° `ğ›¾`ï¼Œä½¿å¾—å¾ˆä¹…ä¹‹å‰çš„æ¢¯åº¦æ–¹å·®ä¸è‡³äºè¿‡å¤šå½±å“å½“å‰çš„æ¢¯åº¦è¯„ä¼°ã€‚

```
v(w, t+1) = ğ›¾v(w, t) + (1-ğ›¾)(J'(ğœ½))^2
```

`v(w, t+1)` ä¼°è®¡äº†è¿‡å»ä¸€æ®µæ—¶é—´å†…ï¼Œè¯¥å‚æ•°ï¼ˆ`w`ï¼‰çš„æ¢¯åº¦é‡çº§ã€‚æ˜¾ç„¶ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ­£æ•°ï¼ˆåˆå§‹å€¼>0çš„è¯ï¼‰ã€‚

æœ€åï¼Œåœ¨æ›´æ–°æ¢¯åº¦çš„æ—¶å€™ï¼Œå°†æ­¥é•¿é™¤ä»¥ `v` çš„å¼€æ–¹ï¼š

```
ğœ½_w,t+1 = ğœ½_w,t - ğœ‚*J'(ğœ½)/sqrt(v(w, t+1))
```

### Adagrad

## Adam

## Adadelta

